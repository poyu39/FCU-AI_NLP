{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  cat  label                                             review\n",
      "0  书籍      1  ﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...\n",
      "1  书籍      1  作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...\n",
      "2  书籍      1  作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...\n",
      "3  书籍      1  作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...\n",
      "4  书籍      1  作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./dataset/online_shopping_10_cats.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                             review\n",
      "0      1  ﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...\n",
      "1      1  作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...\n",
      "2      1  作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...\n",
      "3      1  作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...\n",
      "4      1  作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...\n"
     ]
    }
   ],
   "source": [
    "# 丟掉 cat 欄位 (只需要訓練分類label)\n",
    "\n",
    "df = df.drop(columns=['cat'])\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\BRUCE_~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.427 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                             review\n",
      "0      1  ﻿ 做 父母 一定 要 有 刘墉 这样 的 心态 ， 不断 地 学习 ， 不断 地 进步 ，...\n",
      "1      1  作者 真有 英国人 严谨 的 风格 ， 提出 观点 、 进行 论述 论证 ， 尽管 本人 对...\n",
      "2      1  作者 长篇大论 借用 详细 报告 数据处理 工作 和 计算结果 支持 其新 观点 。 为什么...\n",
      "3      1  作者 在 战 几时 之前 用 了 ＂ 拥抱 ＂ 令人 叫绝 ． 日本 如果 没有 战败 ， ...\n",
      "4      1  作者 在 少年 时即 喜 阅读 ， 能 看出 他 精读 了 无数 经典 ， 因而 他 有 一...\n"
     ]
    }
   ],
   "source": [
    "# jieba 斷詞\n",
    "import jieba\n",
    "\n",
    "def cut_review(review):\n",
    "    review = str(review)\n",
    "    return ' '.join(jieba.cut(review))\n",
    "\n",
    "# df = pd.DataFrame(df['label'], df['review'].astype(str))\n",
    "df['review'] = df['review'].apply(cut_review)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                             review\n",
      "0      1   做 父母 一定 要 有 刘墉 这样 的 心态 不断 地 学习 不断 地 进步 不断 地 给...\n",
      "1      1  作者 真有 英国人 严谨 的 风格 提出 观点 进行 论述 论证 尽管 本人 对 物理学 了...\n",
      "2      1  作者 长篇大论 借用 详细 报告 数据处理 工作 和 计算结果 支持 其新 观点 为什么 荷...\n",
      "3      1  作者 在 战 几时 之前 用 了 拥抱 令人 叫绝 日本 如果 没有 战败 就 有 会 有 ...\n",
      "4      1  作者 在 少年 时即 喜 阅读 能 看出 他 精读 了 无数 经典 因而 他 有 一个 庞大...\n"
     ]
    }
   ],
   "source": [
    "# 清除標點符號\n",
    "import re\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "df['review'] = df['review'].apply(remove_punctuation)\n",
    "\n",
    "# 把多個空白變成一個空白\n",
    "def replace_multi_space(text):\n",
    "    return re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "df['review'] = df['review'].apply(replace_multi_space)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bruce_2nbsnuo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一', '一下', '一些', '一切', '一则', '一天', '一定', '一方面', '一旦', '一时']\n",
      "   label                                             review\n",
      "0      1  做 父母 刘墉 心态 学习 补充 新鲜血液 一颗 年轻 心 想 很 好 孩子 沟通 一个 因...\n",
      "1      1  作者 真有 英国人 严谨 风格 提出 观点 论述 论证 本人 物理学 不深 感受 真理 火花...\n",
      "2      1  作者 长篇大论 借用 详细 报告 数据处理 工作 计算结果 支持 其新 观点 荷兰 县有 欧...\n",
      "3      1  作者 战 拥抱 令人 叫绝 日本 战败 会 美军 占领 没胡 官僚主义 延续 战后 民发 反...\n",
      "4      1  作者 少年 时即 喜 阅读 精读 无数 经典 一个 庞大 内心世界 作品 最 难能可贵 两点...\n"
     ]
    }
   ],
   "source": [
    "# 清除停用詞\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = stopwords.words('chinese')\n",
    "\n",
    "print(stop_words[:10])\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "df['review'] = df['review'].apply(remove_stop_words)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                             review\n",
      "0      1  [做, 父母, 刘墉, 心态, 学习, 补充, 新鲜血液, 一颗, 年轻, 心, 想, 很,...\n",
      "1      1  [作者, 真有, 英国人, 严谨, 风格, 提出, 观点, 论述, 论证, 本人, 物理学,...\n",
      "2      1  [作者, 长篇大论, 借用, 详细, 报告, 数据处理, 工作, 计算结果, 支持, 其新,...\n",
      "3      1  [作者, 战, 拥抱, 令人, 叫绝, 日本, 战败, 会, 美军, 占领, 没胡, 官僚主...\n",
      "4      1  [作者, 少年, 时即, 喜, 阅读, 精读, 无数, 经典, 一个, 庞大, 内心世界, ...\n"
     ]
    }
   ],
   "source": [
    "# 將 review 轉換成 list\n",
    "\n",
    "df['review'] = df['review'].apply(lambda x: x.split(' '))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec\n",
    "import gensim.models as word2vec\n",
    "\n",
    "model = word2vec.Word2Vec(sentences=df['review'], vector_size=300, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('历史', 0.843454897403717),\n",
       " ('观点', 0.8411422371864319),\n",
       " ('读者', 0.8396663665771484),\n",
       " ('文笔', 0.8220207691192627),\n",
       " ('语言', 0.8213810324668884),\n",
       " ('人物', 0.8165594935417175),\n",
       " ('作品', 0.8132500052452087),\n",
       " ('精彩', 0.8101233243942261),\n",
       " ('文章', 0.802902340888977),\n",
       " ('书中', 0.8019985556602478)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('作者')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                             review\n",
      "0      1  [[-0.16006029, 0.12812902, 0.1935148, 0.154932...\n",
      "1      1  [[-0.17674841, 0.013549922, 0.10608046, 0.3584...\n",
      "2      1  [[-0.17674841, 0.013549922, 0.10608046, 0.3584...\n",
      "3      1  [[-0.17674841, 0.013549922, 0.10608046, 0.3584...\n",
      "4      1  [[-0.17674841, 0.013549922, 0.10608046, 0.3584...\n"
     ]
    }
   ],
   "source": [
    "# 將 df['review'] 轉為向量\n",
    "\n",
    "def get_vector(review):\n",
    "    vector = []\n",
    "    for word in review:\n",
    "        try:\n",
    "            vector.append(model.wv[word])\n",
    "        except:\n",
    "            pass\n",
    "    return vector\n",
    "\n",
    "df['review'] = df['review'].apply(get_vector)\n",
    "\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_3_10_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
